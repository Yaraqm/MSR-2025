{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[{"file_id":"1Fu4ztgpX0E5fXLCOutKMR5-v6PmaIztE","timestamp":1731095073832}]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["!pip install peft\n","!pip install huggingface_hub"],"metadata":{"execution":{"iopub.status.busy":"2024-07-08T00:24:43.490072Z","iopub.execute_input":"2024-07-08T00:24:43.490916Z","iopub.status.idle":"2024-07-08T00:25:09.361272Z","shell.execute_reply.started":"2024-07-08T00:24:43.490885Z","shell.execute_reply":"2024-07-08T00:25:09.360329Z"},"trusted":true,"id":"dA8i32FUL8M1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import PeftModel\n","from huggingface_hub import HfApi, HfFolder, Repository\n","\n","# Your Hugging Face token\n","huggingface_token = \"insert hugging face token\"\n","HfFolder.save_token(huggingface_token)\n","\n","# Base model name\n","model_name = \"insert base model\"\n","\n","# Path to the private adapter model\n","adapter_model_path = \"path the adapter model\"\n","\n","# Directory to save the merged model and tokenizer\n","save_directory = \"./merged_model\"\n","\n","# Load the base model\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n",")\n","\n","# Load the tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","# Load the private adapter model with the token\n","ft_model = PeftModel.from_pretrained(base_model, adapter_model_path, use_auth_token=huggingface_token)\n","\n","# Merge the adapter with the base model and unload\n","model2 = ft_model.merge_and_unload()\n","\n","# Save the merged model and tokenizer\n","model2.save_pretrained(save_directory)\n","tokenizer.save_pretrained(save_directory)\n","\n","# Push the model to Hugging Face\n","repository_id = \"insert path\"\n","api = HfApi()\n","api.create_repo(repo_id=repository_id, private=True, exist_ok=True)\n","repository = Repository(local_dir=save_directory, clone_from=repository_id)# This Python 3 environment comes with many helpful analytics libraries installed\n"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-08T00:25:16.580227Z","iopub.execute_input":"2024-07-08T00:25:16.580592Z","iopub.status.idle":"2024-07-08T00:30:31.318769Z","shell.execute_reply.started":"2024-07-08T00:25:16.580563Z","shell.execute_reply":"2024-07-08T00:30:31.317215Z"},"trusted":true,"id":"L73pHzeeL8Mc"},"execution_count":null,"outputs":[]}]}